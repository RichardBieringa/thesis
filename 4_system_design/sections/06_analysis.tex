\section{Analysis}
\label{sec:system:analysis}

A benchmarking instrument is successful if all the stakeholders agree it provides meaningful results. To analyse if the proposed implementation satisfies this we use a set of guidelines established by Folkerts et al. \cite{folkerts2012benchmarking}. In their work they establish three groups of requirements which can be used to evaluate ea benchmarking instrument.

In the remainder of this section we introduce these three groups of requirements and evaluate them against the proposed benchmarking instrument. 

\subsection{General Requirements}
\label{sec:system:analysis:general}
% General Requirements – this group contains generic requirements.

The \textit{General Requirements} group establishes four broad requirements (\ref{gr-1} - \ref{gr-4}). The following list introduces those requirements and discusses how the proposed benchmarking instrument satisfies the conditions.

\begin{enumerate}[label=\textbf{GR\arabic*}, leftmargin=3\parindent]
    \item \textbf{Strong Target Audience}
    \label{gr-1}
    % The target audience must be
    % - considerable size and,
    % - interested to obtain the information.
    

    \item \textbf{Relevant}
    \label{gr-2}
    % The benchmark results have to measure the performance of the typical operation within the problem domain.
    

    \item \textbf{Economical}
    \label{gr-3}
    % The cost of running the benchmark should be affordable.
    

    \item \textbf{Simple}
    \label{gr-4}
    % The benchmark should be understandable, as it creates trust.
    
\end{enumerate}


\subsection{Implementation Requirements}
\label{sec:system:analysis:implementation}
% 2. Implementation Requirements – this group contains requirements regarding

The second group of requirements introduced in the work of Folkerts et al. is the \textit{Implementation Requirements} and establishes requirements (\ref{gr-1} - \ref{gr-4}). The following list introduces those requirements and discusses how the proposed benchmarking instrument satisfies the conditions.


\begin{enumerate}[label=\textbf{IR\arabic*}, leftmargin=3\parindent]
    \item \textbf{Fair and Portable}
    \label{ir-1}
    % All compared systems can participate equally.

    
    \item \textbf{Repeatable}
    \label{ir-2}
    % The benchmark results can be reproduced by rerunning the
    
    \item \textbf{Realistic and Comprehensive}
    \label{ir-3}
    % The workload exercises all SUT features typically used in the major classes of target application

    \item \textbf{Configurable}
    \label{ir-4}
    % a benchmark should provide a flexible performance analysis framework allowing users to configure and customize the workload.
\end{enumerate}


\subsection{Workload Requirements}
\label{sec:system:analysis:workload}
% 3. Workload Requirements – contains requirements regarding the workload definition and its interactions.
The final group of requirements introduced is the \textit{Workload Requirements} and consists of three requirements (\ref{wr-1} - \ref{wr-3}). The following list introduces those requirements and discusses how the proposed benchmarking instrument satisfies the conditions.

\begin{enumerate}[label=\textbf{WR\arabic*}, leftmargin=3\parindent]
    \item \textbf{Representativeness}
    \label{wr-1}
    % The benchmark should be based on a workload scenario that contains a representative set of interactions.
    
    \item \textbf{Scalable}
    \label{wr-2}
    % Scalability should be supported in a manner that preserves
    
    \item \textbf{Metric}
    \label{wr-3}
    % A meaningful and understandable metric is required to report about the SUT reactions to the load

\end{enumerate}